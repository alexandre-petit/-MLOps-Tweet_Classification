{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin\n",
    "\n",
    "#import mlflow\n",
    "#mlflow.set_experiment(\"Mlflow BERT\")\n",
    "\n",
    "import transformers\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Bert\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de préparation des sentences\n",
    "def bert_inp_fct(sentences, bert_tokenizer, max_length) :\n",
    "    input_ids=[]\n",
    "    token_type_ids = []\n",
    "    attention_mask=[]\n",
    "    bert_inp_tot = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        bert_inp = bert_tokenizer.encode_plus(sent,\n",
    "                                              add_special_tokens = True,\n",
    "                                              max_length = max_length,\n",
    "                                              padding='max_length',\n",
    "                                              return_attention_mask = True, \n",
    "                                              return_token_type_ids=True,\n",
    "                                              truncation=True,\n",
    "                                              return_tensors=\"tf\")\n",
    "    \n",
    "        input_ids.append(bert_inp['input_ids'][0])\n",
    "        token_type_ids.append(bert_inp['token_type_ids'][0])\n",
    "        attention_mask.append(bert_inp['attention_mask'][0])\n",
    "        bert_inp_tot.append((bert_inp['input_ids'][0], \n",
    "                             bert_inp['token_type_ids'][0], \n",
    "                             bert_inp['attention_mask'][0]))\n",
    "\n",
    "    input_ids = np.asarray(input_ids)\n",
    "    token_type_ids = np.asarray(token_type_ids)\n",
    "    attention_mask = np.array(attention_mask)\n",
    "    \n",
    "    return input_ids, token_type_ids, attention_mask, bert_inp_tot\n",
    "    \n",
    "\n",
    "# Fonction de création des features\n",
    "def feature_BERT_fct(model, model_type, sentences, max_length, b_size, mode='HF') :\n",
    "    batch_size = b_size\n",
    "    batch_size_pred = b_size\n",
    "    bert_tokenizer = transformers.AutoTokenizer.from_pretrained(model_type)\n",
    "    time1 = time.time()\n",
    "\n",
    "    for step in range(len(sentences)//batch_size) :\n",
    "        idx = step*batch_size\n",
    "        input_ids, token_type_ids, attention_mask, bert_inp_tot = bert_inp_fct(sentences[idx:idx+batch_size], \n",
    "                                                                      bert_tokenizer, max_length)\n",
    "        \n",
    "        if mode=='HF' :    # Bert HuggingFace\n",
    "            outputs = model.predict([input_ids, attention_mask, token_type_ids], batch_size=batch_size_pred)\n",
    "            last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "\n",
    "             \n",
    "        if step ==0 :\n",
    "            last_hidden_states_tot = last_hidden_states\n",
    "            last_hidden_states_tot_0 = last_hidden_states\n",
    "        else :\n",
    "            last_hidden_states_tot = np.concatenate((last_hidden_states_tot,last_hidden_states))\n",
    "    \n",
    "    features_bert = np.array(last_hidden_states_tot).mean(axis=1)\n",
    "    \n",
    "    time2 = np.round(time.time() - time1,0)\n",
    "    print(\"temps traitement : \", time2)\n",
    "     \n",
    "    return features_bert, last_hidden_states_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet_preprocessed</th>\n",
       "      <th>Tweet_preprocessed_dl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1143363</th>\n",
       "      <td>4</td>\n",
       "      <td>im so sleepy still not at home but we are done...</td>\n",
       "      <td>i'm so sleepy! still not at home but we are do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151624</th>\n",
       "      <td>4</td>\n",
       "      <td>dad give you a breaknever  you wouldnt love me...</td>\n",
       "      <td>dad give you a break...never! .... you wouldn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095989</th>\n",
       "      <td>4</td>\n",
       "      <td>be out there dont worry im done w my elongate...</td>\n",
       "      <td>be out there, dont worry, im done w  my elon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220694</th>\n",
       "      <td>4</td>\n",
       "      <td>im on my way to the beach</td>\n",
       "      <td>i'm on my way to the beach!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569897</th>\n",
       "      <td>4</td>\n",
       "      <td>wowhungarynice to know u here</td>\n",
       "      <td>wow..hungary...nice to know u here.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target                                 Tweet_preprocessed  \\\n",
       "1143363       4  im so sleepy still not at home but we are done...   \n",
       "1151624       4  dad give you a breaknever  you wouldnt love me...   \n",
       "1095989       4   be out there dont worry im done w my elongate...   \n",
       "1220694       4                          im on my way to the beach   \n",
       "1569897       4                      wowhungarynice to know u here   \n",
       "\n",
       "                                     Tweet_preprocessed_dl  \n",
       "1143363  i'm so sleepy! still not at home but we are do...  \n",
       "1151624  dad give you a break...never! .... you wouldn'...  \n",
       "1095989    be out there, dont worry, im done w  my elon...  \n",
       "1220694                        i'm on my way to the beach!  \n",
       "1569897                wow..hungary...nice to know u here.  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed_tweet.csv')\n",
    "df = df.sample(n=1000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment were not used when initializing TFRobertaModel: ['classifier']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "max_length = 64\n",
    "batch_size = 100\n",
    "model_type = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "model = transformers.TFAutoModel.from_pretrained(model_type)\n",
    "sentences = df['Tweet_preprocessed_dl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, LSTM, RepeatVector, Dense, TimeDistributed\n",
    "\n",
    "model = Sequential(name=\"LSTM-Model\") # Model\n",
    "model.add(Input(shape=(X_train.shape[1],X_train.shape[2]), name='Input-Layer')) # Input Layer - need to speicfy the shape of inputs\n",
    "model.add(Bidirectional(LSTM(units=32, activation='tanh', recurrent_activation='sigmoid', stateful=False), name='Hidden-LSTM-Encoder-Layer')) # Encoder Layer\n",
    "model.add(RepeatVector(Y_train.shape[1], name='Repeat-Vector-Layer')) # Repeat Vector\n",
    "model.add(Bidirectional(LSTM(units=32, activation='tanh', recurrent_activation='sigmoid', stateful=False, return_sequences=True), name='Hidden-LSTM-Decoder-Layer')) # Decoder Layer\n",
    "model.add(TimeDistributed(Dense(units=1, activation='linear'), name='Output-Layer')) # Output Layer, Linear(x) = x\n",
    "\n",
    "##### Step 4 - Compile the model\n",
    "model.compile(optimizer='adam', # default='rmsprop', an algorithm to be used in backpropagation\n",
    "              loss='mean_squared_error', # Loss function to be optimized. A string (name of loss function), or a tf.keras.losses.Loss instance.\n",
    "              metrics=['MeanSquaredError', 'MeanAbsoluteError'], # List of metrics to be evaluated by the model during training and testing. Each of this can be a string (name of a built-in function), function or a tf.keras.metrics.Metric instance. \n",
    "              loss_weights=None, # default=None, Optional list or dictionary specifying scalar coefficients (Python floats) to weight the loss contributions of different model outputs.\n",
    "              weighted_metrics=None, # default=None, List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.\n",
    "              run_eagerly=None, # Defaults to False. If True, this Model's logic will not be wrapped in a tf.function. Recommended to leave this as None unless your Model cannot be run inside a tf.function.\n",
    "              steps_per_execution=None # Defaults to 1. The number of batches to run during each tf.function call. Running multiple batches inside a single tf.function call can greatly improve performance on TPUs or small models with a large Python overhead.\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [model(feature) for feature in encoded_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[-2.170981 , -0.8745634,  3.8376608]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = LogisticRegression(**params, random_state=42)\n",
    "        \n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "        \n",
    "        average_score = round(sum(scores) / 5, 3)\n",
    "        \n",
    "        loss = 1 - average_score\n",
    "        \n",
    "        \n",
    "        mlflow.log_metric('Accuracy', average_score)\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        return {'loss': loss, 'params': params, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'tol': hp.uniform('tol', 0.00001, 0.0001),\n",
    "    'C': hp.uniform('C', 0.05, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Target'].copy()\n",
    "X = df['Tweet_preprocessed_dl'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[X_train.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_name = \"tfidf\"\n",
    "\n",
    "vectorizer_params = {\"stop_words\": \"english\", \"max_df\": 0.95, \"min_df\": 1}\n",
    "\n",
    "vectorizers = {\n",
    "    'count-vectorizer': CountVectorizer(**vectorizer_params),\n",
    "    'tfidf': TfidfVectorizer(**vectorizer_params)\n",
    "}\n",
    "\n",
    "vectorizer = vectorizers[vectorizer_name]\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "bayes_trials = Trials()\n",
    "\n",
    "with mlflow.start_run(run_name=\"hyperopt_logistic\") as run:\n",
    "    best = fmin(fn=objective, space=space, algo=tpe_algorithm, max_evals=10, trials=bayes_trials)\n",
    "    best = {key:float(value) for key, value in best.items()}\n",
    "    \n",
    "    \n",
    "    mlflow.log_dict(best, \"best_params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from itertools import product\n",
    "\n",
    "params = {\n",
    "    'tol': [0.00001, 0.0001],\n",
    "    'C': [0.05, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    for t, c in product(params['tol'], params['C']):\n",
    "    \n",
    "        mlflow.log_params({\"vectorizer\": vectorizer_name})\n",
    "        \n",
    "        print(f\"training model with params: tol:{t}, C:{c}\")\n",
    "        \n",
    "        model = LogisticRegression(tol=t, C=c, max_iter=1000)\n",
    "        \n",
    "        start = perf_counter()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        end = perf_counter()\n",
    "        \n",
    "        duration = round(end - start, 2)\n",
    "        \n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"{score=}\")\n",
    "        mlflow.log_metric(\"accuracy\", score)\n",
    "        mlflow.log_metric(\"duration\", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Bert_model\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    #mlflow.log_params({\"vectorizer\": vectorizer_name})\n",
    "    \n",
    "    start = perf_counter()\n",
    "\n",
    "    bert_model.fit\n",
    "    \n",
    "    \n",
    "    y_pred = bert_model.predict(X_test)\n",
    "    \n",
    "    end = perf_counter()\n",
    "    \n",
    "    duration = round(end - start, 2)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", score)\n",
    "    mlflow.log_metric(\"duration\", duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
